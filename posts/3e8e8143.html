<!DOCTYPE html><html lang="zh-CN" color-mode="light"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv="X-UA-Compatible" content="ie=edge"><title>GPU 工作原理 - 樱白</title><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="google" content="notranslate"><meta name="google-site-verification" content="eQV1-bjl_nNjXCj2YhmaG3IHeUK9wO34JUX--01e0yI"><meta name="msvalidate.01" content="81DEE48B3A7B549DEC6C5C66F0BB05C2"><meta name="keywords" content="Cherry,White,CherryWhite,博客,个人成长, gpu"><meta name="description" content="为什么GUP计算是可行的（我的数据在哪里）Flops(..."><meta name="author" content="樱白 - Cherry White"><link rel="icon" href="/images/icons/favicon-16x16.ico" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.ico" type="image/png" sizes="32x32"><link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.jpg" sizes="180x180"><meta rel="mask-icon" href="/images/icons/stun-logo.svg" color="#333333"><meta rel="msapplication-TileImage" content="/images/icons/favicon-128x128.ico"><meta rel="msapplication-TileColor" content="#000000"><link rel="canonical" href="https://cherry-white.github.io/posts/3e8e8143.html"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/lib/iconfont/iconfont.css"><link rel="stylesheet" href="/lib/fancybox/fancybox.css"><link rel="stylesheet" href="/lib/highlight/a11y-dark.css"><script>var CONFIG=window.CONFIG||{},ZHAOO=window.ZHAOO||{},CONFIG={isHome:!1,fancybox:!0,pjax:!1,loading:{gif:"/images/theme/loading.gif",lottie:""},lazyload:{enable:!0,only_post:"false",loading:{gif:"/images/theme/loading.gif",lottie:""}},donate:{enable:!0,alipay:"/images/pay/alipay.png",wechat:"/images/pay/wechat.jpg"},galleries:{enable:!0},fab:{enable:!0,always_show:!1},carrier:{enable:!0},daovoice:{enable:!1},preview:{background:{default:"",api:"https://api.mtyqx.cn/api/random.php"},motto:{default:"我在开了灯的床头下，想问问自己的心啊。",typing:!0,api:"https://v2.jinrishici.com/one.json",data_contents:'["data","content"]'}},qrcode:{enable:!0,type:"url",image:"https://pic.izhaoo.com/weapp-code.jpg"},toc:{enable:!0},scrollbar:{type:"normal"},notification:{enable:!1,delay:4500,list:"",page_white_list:"",page_black_list:""},search:{enable:!0,path:"search.xml"}}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9139831305743788" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style></head><body class="lock-screen"><div class="loading" id="loading"></div><nav class="navbar"><div class="left"><i class="iconfont iconhome j-navbar-back-home"></i> <i class="iconfont iconqrcode j-navbar-qrcode"></i> <i class="iconfont iconmoono" id="color-toggle" color-toggle="light"></i> <i class="iconfont iconsearch j-navbar-search"></i></div><div class="center">GPU 工作原理</div><div class="right"><i class="iconfont iconmenu j-navbar-menu"></i></div><div id="qrcode-navbar"></div></nav><nav class="menu"><div class="menu-container"><div class="menu-close"><i class="iconfont iconbaseline-close-px"></i></div><ul class="menu-content"><li class="menu-item"><a href="/" class="underline">首页</a></li><li class="menu-item"><a href="javascript:toRandomPost()" rel="external nofollow noreferrer" class="underline">随机</a></li><li class="menu-item"><a href="/galleries/" class="underline">画廊</a></li><li class="menu-item"><a href="/archives/" class="underline">归档</a></li><li class="menu-item"><a href="/tags/" class="underline">标签</a></li><li class="menu-item"><a href="/categories/" class="underline">分类</a></li><li class="menu-item"><a href="/about/" class="underline">关于</a></li></ul><div class="menu-copyright"><p>Powered by <a target="_blank" href="https://hexo.io" rel="external nofollow noreferrer">Hexo</a> | Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo" rel="external nofollow noreferrer">zhaoo</a></p><p>Cherry White .All Rights Reserved Copyright © 2021</p></div></div></nav><main id="main"><div class="article-wrap"><div class="row container"><div class="col-xl-3"></div><div class="col-xl-6"><article class="article"><div class="wrap"><section class="head"><img   class="lazyload" data-original="/images/background/GPU-Working-Principle.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  draggable="false"><div class="head-mask"><h1 class="head-title">GPU 工作原理</h1><div class="head-info"><span class="post-info-item"><i class="iconfont iconcalendar"></i>九月 04, 2022</span> <span class="post-info-item"><i class="iconfont iconfont-size"></i>4328</span></div></div></section><section class="main"><section class="content"><h2 id="为什么GUP计算是可行的（我的数据在哪里）"><a href="#为什么GUP计算是可行的（我的数据在哪里）" class="headerlink" title="为什么GUP计算是可行的（我的数据在哪里）"></a>为什么GUP计算是可行的（我的数据在哪里）</h2><p>Flops(每秒种浮点运算次数)跟机器的算力有关<br>在购买机器的时候 nobody cares about flops 或者说 almost nobody really cares about flops</p><p>CPU大约每秒能进行2万次的双精度（FP64）运算。<br>内存将数据传送到CPU，每秒传输大约200G字节，也就是每秒25G的FP64数值。<br>因为每个FP64是8字节，所以内存每秒可以提供250亿个FP64值，CPU每秒能处理2万亿个FP64数据</p><p>每秒内存需要同时传输80次数据给CPU才能让CPU满载<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/ComputeIntensity.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">计算强度</span></p><p>不同CPU的计算强度都差不多，Flops处理能力越强就会有更大的内存带宽来平衡它，<br>当Flops的速度比内存宽带的速度块，计算强度就会上升<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/CPUVSGPU.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">CPU vs GPU</span></p><p>因为Flops被内存带宽完全的限制住了，随意每次加载100个程序是十分困难的，<br>这还不是全部，我们更关心的是延迟（Latency）而不是内存带宽（Memory bandwidth）<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Because.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">Because</span></p><p>通过方程aX + Y &#x3D; Z，分别加载X和Y等待延迟读取到数据后进行计算得到结果，这就是核心的指令流水线<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Daxpy.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">数乘(daxpy)</span></p><p>在一个时钟周期内光传播的距离只有10厘米，所以时钟频率太快而光走不了多远。<br>电流在硅中的传播速度只有光的五分之一（6万公里&#x2F;秒），<br>一个时钟周期内，电流的移动只有20毫米。<br>内存到CPU的路程需要有5-7个时钟周期的延迟，因为物理上的原因，<br>在内存中提取数据时需要5-10个时钟周期才能放回到CPU。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Distance.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">内存到CPU距离</span></p><p>CPU很快，内存很慢。所以整体效率很低<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Utilization.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">利用率</span></p><p>虽然0.14%的利用率很低，但是已近算很好了，这就是程序受到了延迟限制（latency bound）的影响，<br>它发生次数远比我们认为的要多。延迟限制是内存限制类别的一个子集，<br>它主要发生在不需要立即从内存中检索太多的数据，但是在内存层次结构的上层，<br>必须等待很长事件才能将数据发送到处理器的情况。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/UtilizationComparison.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">利用率对比</span></p><p>GPU要充分利用内存，按起前面的数据 11659&#x2F;16&#x3D;729 一次需要运行729次迭代才能让内存保存满负荷运转<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/GPUUtilization.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">GPU利用率</span></p><h3 id="Loop-Unrolling（循环展开）"><a href="#Loop-Unrolling（循环展开）" class="headerlink" title="Loop Unrolling（循环展开）"></a>Loop Unrolling（循环展开）</h3><p>编译器有一种优化器叫做Loop Unrolling（循环展开）</p><ul><li>循环展开可以由程序员完成，也可由编辑器自动优化完成。</li><li>循环展开是通过将循环体代码复制多次实现</li><li>循环展开能够增大指令调度的空间，减少循环分支指令的开销</li><li>循环展开可以更好的实现数据预取技术</li></ul><p>循环展开发现只有一个进程和延迟时间，通过发出back to back all at once信号加载 x 和 y<br>一次循环中可以做很多次，它受到硬件能跟踪多少操作请求的限制，它可以在指令流水线中缓存指令，<br>但是它必须追踪每一个请求。虽然我只有一个进程，但循环展开之后有729个迭代请求也没问题<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/GPUParallel.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">GPU并行计算</span></p><p>并行性（parallelism）比并发性（concurrency）强，对吗？</p><ul><li>并行的关键是你有同时处理多个任务的能力（每个线程同时执行一个操作，但是硬件可以处理许多线程）</li><li>并发的关键是你有处理多个任务的能力，不一定要同时</li></ul><h3 id="GPU和CPU对比"><a href="#GPU和CPU对比" class="headerlink" title="GPU和CPU对比"></a>GPU和CPU对比</h3><p>我们可以通过循环展开多线程操作提高硬件的使用效率，同样也允许我使用较少的线程。<br>GPU比CPU不同的是有更高的延迟和更多的线程。<br>如果有一些线程正在等待内存，那么还有更多的线程等待激活，GPU就是所谓的吞吐机。<br>GPU的设计师将所有资源投入到更多线程中而不是减少延迟。<br>CPU是一台延迟机，CPU的期望是一个线程基本完成所有的工作，<br>将一个线程从一个切换到另一个是非常昂贵的，就像上下文切换一样。<br>所以你只需要足够的线程就可以解决延迟的问题，而CPU设置值把所有的资源都投入到减少延迟上了。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Contrast.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">对比</span></p><h2 id="介绍GPU"><a href="#介绍GPU" class="headerlink" title="介绍GPU"></a>介绍GPU</h2><p>GPU解决的方式和CPU完全不同，但是内存是最重要的，所有的程序都是和内存相关，<br>内存带宽、内存延迟以及数据在内存中的位置。</p><h3 id="缓存（Cache）"><a href="#缓存（Cache）" class="headerlink" title="缓存（Cache）"></a>缓存（Cache）</h3><p>我把寄存器（Register File）作为Cache的一种，这是一个非常重要的GPU细节，<br>GPU在每个线程中使用大量的寄存器，寄存器能够以很低的延迟来保存活动的数据，<br>因为不同类型的缓存延迟差距很大。硬件需要一个地方存储指针，<br>所以当我从内存中加载数据并放到寄存器中，我就可以计算它了，<br>我可做的内存操作与寄存器的数量直接相关，GPU使用寄存器缓存数据解决高延迟问题，以及通过靠近数据来减少延迟。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Cache.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">缓存</span></p><p>L1、L2、HBM缓存结构总览<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/CacheContrast.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">缓存对比</span></p><p>L1、L2、HBM缓存，L1的带宽是最强的，PCIe是最差的，PCIe在这里没有作用，<br>只是因为它连接GPU和CPU，但我认为NVLink比PCIe更接近主内存领域，NVLink是GPU之间相连的<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/CacheContrast2.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">缓存对比2</span></p><p>带宽在增加，你需要为主内存准备几乎相同数量的线程（下图是39264），<br>因为计算强度很高，所以如果这个内存系统中有一个比其他需要更多的线程，就会发现它的瓶颈，<br>我必须加入更多线程去满足那部分，然后我的内存系统的其他部分便会拥有更多线程，这是一种精心设计的平衡。</p><p><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/CacheContrast3.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">缓存对比3</span></p><p>SM是一个基础处理单元，它里面有很多东西，实际上要记住的是warp，它有32个线程组成一组，<br>warp就是GPU的基本调度单位，在一个时钟周期内，我可以运行多个warp，一个SM，包含64个warps，<br>4个warps可以并行运行。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/SM.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">SM</span></p><p>每个SM 2048个线程，120个线程我一次就能跑完了，这就是我说的GPU是超量配额的原因。<br>当一些线程因为等待延迟关闭时，其他线程大概已经收到了他们的响应，准备运行了（随时切换线程），<br>这就是GPU工作的全部秘密， 它可以在不同warp之间切换，并且在一个时钟周期内完成，所以根本没有上下文开销。<br>GPU可以连续运行线程，这意味着系统在任何我时候都能运行更多的线程是非常重要的，因为这是解决延迟的好方法。<br>为什么不希望固定线程，因为GPU是一个吞吐机<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/SM2.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">SM2</span></p><p>汽车不能快速有效的帮助其他人，他只能载少数人从一个地方到另一个地方，<br>火车可以载很多人，会停很多地方，所以在这条线路上的所有人都能得到帮助，<br>而且沿途可以有很多火车，关于延迟系统很可怕的一个事就是过载，<br>开车如果路上太多车你哪里都去不到，火车满了可以等下一列，<br>GPU是一个吞吐机，就像火车一样，让你在站台等，而且需要保持忙碌，<br>而CPU是一个延迟机，切换线程开销很大，所以需要一个线程尽快的运行。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/ThroughputMachineAndDelayMachine.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">吞吐机和延迟机</span></p><ul><li>元素智能算法（Element-wise）：两个张量之间操作，它在对应张量内的元素进行操作</li><li>Local：比如卷积，它会引入所有邻居</li><li>all to all：比如傅里叶转换（Fourier Transform），要求每个元素与其他元素相互作用</li></ul><p><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Algorithm.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">算法</span></p><h3 id="如何获取吞吐量"><a href="#如何获取吞吐量" class="headerlink" title="如何获取吞吐量"></a>如何获取吞吐量</h3><p>一张猫的图片，将用一个网格覆盖，将网格创建许多工作块，随每个方块单独进行处理，<br>让这些方块彼此独立处理图像的不同部分，GPU通过超量分配（oversubscribe）加载这些块，<br>我们想要的是高效执行和内存满载使用。因此，多个块由许多一起工作的线程组成，<br>这些线程可以共享数据并实现联合任务，该块中的所有线程同时并行运行。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/GetThroughput.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">获取吞吐量</span></p><p>要做工作，都被分解成线程块，每个块都有并行线程，确保线程同时运行，这样他们就可以共享数据，<br>但所有块都是超量分配模式下独立调度的。我需要通过吞吐机器保持忙碌，但它也允许一定数量的线程相互交互，<br>这就是GPU编程的本质<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/IndependentDispatching.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">独立调度</span></p><p>延迟才是我真正要关心的，所有这些线程都是通过超量分配：程序、网格模型、线程，<br>所有的都在我的块中运行，从根本上解决延迟问题。</p><p>现在我有很多线程，根据前面那个表，我有5倍的线程，远远超过我需要的线程，问题是那么多的线程如何调度。<br>这归结到算法的复杂性，也就是说，我增加问题的规模，我可以增加很多线程，但我要怎么操作呢？<br>例如对于Element-wise，每次我添加一个线程，我都加载一个新的数据元素，但是我只做了一次操作，<br>我添加了一个线程，加载数据一部分，载做一个计算，我添加的线程实际上不会带来变化，我所请求的Flops增加了，<br>但我的算法以及算法的强度是平滑的，比如2D、卷积或者3D。我现在的数据，当我增加方块是，它是可扩展的。<br>它的算术强度是1：1计算，在卷积中即使再多的数据也无法与我的计算强度抗衡（线程和计算量同时增大）。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/IndependentDispatching2.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">独立调度2</span></p><p>矩阵乘法是一个大而复杂的东西，但它是由大量的FMA（Fused-Multiply-Add）堆积起来的。<br>它重复计算很多次，这个矩阵每个绿点装载25次，我只处理了这一行并用作25次计算，<br>如果矩阵是10X10，我会以100次操作的速度重复使用它，这就是我想要的计算机强度，<br>因此，随着矩阵的增长，极大地提高我的Flops能力<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/Matrix.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">矩阵</span></p><p>所以矩阵乘法具有算术强度，它增加矩阵立方的大小，这就是矩阵乘法的本质。<br>同时，随着矩阵变大，数据加载量承指数级增加，我已经对正在加载的数据增添了指数，<br>所以我的算术强度、扩展性、算法复杂度是有序的。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/MatrixMultiplication.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">矩阵相乘</span></p><p>这两个线的交点在50，一旦矩阵大小达到50，我们就会获取所有数据，为了满足Flops需求，<br>计算机会抓取所有它能处理的数据，所以这就是我能有效计算的最大矩阵，我的内存现在比计算要空闲的多，<br>理想情况下，为了让你的机器保存平衡，需要让一切都以100%的速度运行，这就是吞吐机的意义所在，<br>所以最佳点就是这条线的交点。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/EffectiveCalculation.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">有效计算</span></p><p>下图是FP32和FP64的交点的比较，计算强度100的线，到达100将会达到双精度计算的最大值，<br>当然，随着矩阵增大，内存会变得越来越空闲，因为我要花越来越多的时间来计算。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/EffectiveCalculationComparison.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">有效计算对比</span></p><p>所以现在我们可以引入Tensor Core，Tensor Core是内置在SM中的定制硬件单元，<br>很像一个算术单元，我可以乘或加运算，但是它们可以一次性完成整个矩阵运算，<br>这意味着它们可以一步完成多个Flops请求任务，FMA每个指令可以做两个乘加运算，<br>它为每个指令增加了两个Flops，这些张量核心能够比Cuda核心实现更多的Flops。<br>我想要跑到更快，但是更大的Flops需要更大的问题规模，当内存空间用完时，就无法增大Flops了。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/TensorCore.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">Tensor Core</span></p><p>HBM计算强度有400，这就是为什么它需要使用HBM内存进行操作。<br>如果使用L2缓存，我都计算强度只有156，L1更小，只有32，<br>所以我显然需要使用缓存来搭配我的张量核心，使它在最小矩阵下更高效。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/CacheContrast2.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">缓存对比2</span></p><p>在我的主存储器里是400，L2是156，L1中是32，我可以快速处理小矩阵，因为我已经改变数据所在的位置。<br><img   class="lazyload" data-original="/images/article/GPUWorkingPrinciple/CacheContrast4.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ><span class="image-caption">缓存对比4</span></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bilibili.com/video/BV17L4y1a7Xy?spm_id_from=333.880.my_history.page.click&vd_source=371bc0e94a8c97f991c4ac20af0b2d53">参考视频</a></p></section><section class="extra"><ul class="copyright"><li><strong>本文作者：</strong>樱白 - Cherry White</li><li><strong>本文链接：</strong><a href="https://cherry-white.github.io/posts/3e8e8143.html" title="https:&#x2F;&#x2F;cherry-white.github.io&#x2F;posts&#x2F;3e8e8143.html">https:&#x2F;&#x2F;cherry-white.github.io&#x2F;posts&#x2F;3e8e8143.html</a></li><li><strong>版权声明：</strong>本博客所有文章均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" title="BY-NC-SA" target="_blank" rel="noopener external nofollow noreferrer">BY-NC-SA</a> 许可协议，转载请注明出处！</li></ul><section class="donate"><div id="qrcode-donate"><img   class="lazyload" data-original="/images/pay/alipay.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ></div><div class="icon"><a href="javascript:;" rel="external nofollow noreferrer" id="alipay"><i class="iconfont iconalipay"></i></a> <a href="javascript:;" rel="external nofollow noreferrer" id="wechat"><i class="iconfont iconwechat-fill"></i></a></div></section><ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/gpu/" rel="tag">gpu</a></li></ul><nav class="nav"><a href="/posts/27ef4ad0.html"><i class="iconfont iconleft"></i>现代游戏引擎 - 游戏渲染中光和材质的数学魔法（五）</a> <a href="/posts/3d4c0b0.html">现代游戏引擎 - 游戏引擎中的渲染实践（四）<i class="iconfont iconright"></i></a></nav></section><section class="comments"><div class="btn" id="comments-btn">查看评论</div><link rel="stylesheet" href="/lib/gitalk/gitalk.css"><div id="gitalk" class="gitalk"></div><script src="/lib/gitalk/gitalk.js"></script><script>const title=window.location.pathname.substring(0,50);window.onload=function(){const e=new Gitalk({clientID:"5d2553717eea46759e10",clientSecret:"4d93ce39e65dd2c5b9e364f75d06efd73c64a8ba",id:title,repo:"cherry-white.github.io",owner:"cherry-white",admin:"cherry-white",proxy:"https://vercel.prohibitorum.top/github_access_token"});$("#comments-btn").on("click",function(){$(this).hide(),e.render("gitalk")})}</script></section></section></div></article></div><div class="col-xl-3"><aside class="toc-wrap"><h3 class="toc-title">文章目录：</h3><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88GUP%E8%AE%A1%E7%AE%97%E6%98%AF%E5%8F%AF%E8%A1%8C%E7%9A%84%EF%BC%88%E6%88%91%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%89"><span class="toc-text">为什么GUP计算是可行的（我的数据在哪里）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Loop-Unrolling%EF%BC%88%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80%EF%BC%89"><span class="toc-text">Loop Unrolling（循环展开）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU%E5%92%8CCPU%E5%AF%B9%E6%AF%94"><span class="toc-text">GPU和CPU对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8DGPU"><span class="toc-text">介绍GPU</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%EF%BC%88Cache%EF%BC%89"><span class="toc-text">缓存（Cache）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E5%90%9E%E5%90%90%E9%87%8F"><span class="toc-text">如何获取吞吐量</span></a></li></ol></li></ol></aside></div></div></div></main><footer class="footer"><div class="footer-social"><a href="tencent://message/?Menu=yes&uin=1789139001" target="_blank" class="footer-social-item" onmouseover='this.style.color="#12B7F5"' onmouseout='this.style.color="#33333D"'><i class="iconfont iconQQ"></i> </a><a href="/images/contact/wechat.jpg" target="_blank" class="footer-social-item" onmouseover='this.style.color="#09BB07"' onmouseout='this.style.color="#33333D"'><i class="iconfont iconwechat-fill"></i> </a><a href="https://cherry-white.github.io/" target="_blank" class="footer-social-item" onmouseover='this.style.color="#DA2E76"' onmouseout='this.style.color="#33333D"'><i class="iconfont iconinstagram"></i> </a><a href="https://gitee.com/zj1789139001" target="_blank" class="footer-social-item" onmouseover='this.style.color="#9f7be1"' onmouseout='this.style.color="#33333D"'><i class="iconfont icongithub-fill"></i> </a><a href="mailto:1789139001@qq.com" target="_blank" class="footer-social-item" onmouseover="this.style.color=#FF3B00" onmouseout='this.style.color="#33333D"'><i class="iconfont iconmail"></i></a></div><div class="footer-copyright"><p>Powered by <a target="_blank" href="https://hexo.io" rel="external nofollow noreferrer">Hexo</a> | Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo" rel="external nofollow noreferrer">zhaoo</a></p><p>Cherry White .All Rights Reserved Copyright © 2021</p></div></footer><div class="fab fab-plus"><i class="iconfont iconplus"></i></div><a href="https://support.qq.com/product/368715" rel="external nofollow noreferrer" target="_blank"><div class="fab fab-tencent-chao"><i class="iconfont iconcomment"></i></div></a><div class="fab fab-up"><i class="iconfont iconcaret-up"></i></div><script src="/js/color-mode.js"></script><div class="search"><div class="search-container"><div class="search-close"><i class="iconfont iconbaseline-close-px"></i></div><div class="search-input-wrapper"><i class="search-input-icon iconfont iconsearch"></i> <input class="search-input" type="search" id="search-input" placeholder="Search..." autofocus autocomplete="off" autocorrect="off" autocapitalize="off"></div><div class="search-output" id="search-output"></div></div></div></body><script src="/lib/jquery/jquery.js"></script><script src="/lib/lazyload/lazyload.js"></script><script src="/lib/fancybox/fancybox.js"></script><script src="/lib/qrcode/qrcode.js"></script><script src="/js/utils.js"></script><script src="/js/script.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0],e=(t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}()</script><script defer src="https://hm.baidu.com/hm.js?3cbbee458915615f7e2e5b7a073f2113"></script><script src="https://fastly.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script><script src="/random.js"></script></html>